% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/partim.R
\name{partim}
\alias{partim}
\alias{partim.formula}
\alias{partim.default}
\title{Partition Importance}
\usage{
partim(x, ...)

\method{partim}{formula}(
  formula,
  data,
  method = c("tree_entropy", "tree_lmg", "tree_pmvd"),
  ...,
  fEstimate = stats::lm.fit,
  fExplain = NULL,
  fCluster = NULL
)

\method{partim}{default}(
  x,
  y,
  method = c("tree_entropy", "tree_lmg", "tree_pmvd"),
  add_intercept = TRUE,
  ...,
  fEstimate = stats::lm.fit,
  fExplain = NULL,
  fCluster = NULL
)
}
\arguments{
\item{x}{the class of \code{object} determines which method is used. Can be either 'formula' or an object coercible to 'data.frame'. When it is a 'data.frame' it contains independent variables for the regression. Each row is an observation vector.}

\item{...}{additional arguments passed to the fitting functions 'fEstimate' and 'fExplain'}

\item{formula}{an object of class 'formula': a symbolic description of the model to be fitted.}

\item{data}{a 'data.frame' or an object coercible to 'data.frame' that contains all data referenced in \code{formula}.}

\item{method}{method to use to partition importance among clusters. See Details.}

\item{fEstimate}{a function that takes arguments \code{x} and \code{y} and fits a regression model. This method is used to fit the initial regression of \code{y} on \code{x}, which is explained using fExplain. Must return an object with a 'fitted.values' attribute. Default: \code{stats::lm.fit}.}

\item{fExplain}{a function that takes arguments \code{x} and \code{y} and fits a regression model. The default behavior uses \code{fEstimate} for both model fitting and explaining, but different methods can be used by supplying an \code{fExplain} function. Must return an object with a 'fitted.values' attribute. Default: equal to \code{fEstimate}.}

\item{fCluster}{a function that takes an argument \code{x} and returns a vector of length \code{ncol(x)} which assigns the columns in \code{x} to exactly two clusters.}

\item{y}{numerical response variable.}

\item{add_intercept}{bool (default: TRUE). Should an intercept be added to \code{x}.}
}
\value{
A named vector of importance values for each variable.
}
\description{
\code{partim} calculates importance metrics for different types of regression models using a tree partitioning approach.
}
\details{
Partition Importance is a procedure to obtain variable importance values for a regression model that sum to the \eqn{R^2} of the regression.

The importance values approximate Shapley regression values (also known as 'LMG' (Lindeman \emph{et al.}, 1980) or dominance analysis), however are less computationally complex and only require calculation of \eqn{2k} instead of \eqn{2^k} regressions (where \eqn{k} is the number of features). This is achieved by computing explanations using a recursion along the branches of a hierarchical graph and calculation of coalition importance values at each split along the graph.

Partition importance is model agnostic in the sense that any type of regression model (including regularized or nonlinear models) can be passed to \code{fEstimate} and \code{fExplain}. Here \code{fEstimate} is used to obtain initial fitted values of the model which are recursively explained, while \code{fEstimate} is the model that is used when calculating coalition Shapley values at each split. By default \code{fExplain} simply uses \code{fEstimate}, but the option exists to pass separate models here.

At each split in the hierarchical graph coalition Shapley values are calculated using different weighting schemes given by \code{type}:
\itemize{
\item \code{type = 'tree_lmg'} splits the common explanatory component equally between the two branches
\item \code{type = 'tree_pmvd'} splits the common component in proportion to the unique explanatory component (analogous to PMVD algorithm (Feldman, 2005))
\item \code{type = 'tree_entropy'} splits the common component based on the entropy of common variance loadings in each branch. This corrects the structural bias introduced by the hierarchical graph to some degree and typically performs better than the preceding methods at approximating LMG values.
}
}
\examples{
data <- MASS::Boston
partim(medv ~ ., data, method = "tree_entropy")

# Custom clustering function
partim(medv ~ ., data, fCluster = fCluster(type = "agnes", method = "ward"))

# Explain a robust regression
partim(medv ~ ., data, fEstimate = MASS::rlm)

}
\references{
Lindeman RH, Merenda PF, Gold RZ (1980). Introduction to Bivariate and Multivariate Analysis.
Scott, Foresman, Glenview, IL.

Feldman, B. (2005) Relative Importance and Value SSRN Electronic Journal.
}
\seealso{
\code{\link{fCluster}}, \code{\link{fEstimate}}
}
\author{
Johann Pfitzinger
}
